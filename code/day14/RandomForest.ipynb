{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest vs Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in Titanic Data\n",
    "titanic = pd.read_csv(\"../../datasets/titanic/train.csv\")\n",
    "\n",
    "titanic_only = pd.get_dummies(titanic,columns=['Sex','Pclass','Embarked'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop columns we don't care about (yet) or have missing values (Models don't like missing values)\n",
    "titanic_only.drop(['PassengerId','Name','Ticket','Age','Cabin'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train Test Splitting\n",
    "local_train, local_test = train_test_split(titanic_only,test_size=0.2,random_state=123)\n",
    "local_train.shape\n",
    "local_test.shape\n",
    "\n",
    "local_train_y = local_train[\"Survived\"]\n",
    "local_train_x = local_train.drop([\"Survived\"],axis=1)\n",
    "local_test_y = local_test[\"Survived\"]\n",
    "local_test_x = local_test.drop(\"Survived\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497509\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "#The Logistic Regression Model\n",
    "clf = sm.Logit(local_train_y,local_train_x)\n",
    "result = clf.fit()\n",
    "preds = result.predict(local_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of Logistic Model\n",
    "np.mean((preds > 0.5) == local_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69      ,  0.31      ],\n",
       "       [ 0.86251132,  0.13748868],\n",
       "       [ 0.97333333,  0.02666667],\n",
       "       [ 0.88283333,  0.11716667],\n",
       "       [ 0.7875    ,  0.2125    ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.02741703,  0.97258297],\n",
       "       [ 0.12902858,  0.87097142],\n",
       "       [ 0.75916667,  0.24083333],\n",
       "       [ 0.63      ,  0.37      ],\n",
       "       [ 0.88      ,  0.12      ],\n",
       "       [ 0.18483333,  0.81516667],\n",
       "       [ 0.03      ,  0.97      ],\n",
       "       [ 0.87476399,  0.12523601],\n",
       "       [ 0.035     ,  0.965     ],\n",
       "       [ 0.16      ,  0.84      ],\n",
       "       [ 0.01      ,  0.99      ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.77      ,  0.23      ],\n",
       "       [ 0.97016667,  0.02983333],\n",
       "       [ 0.6       ,  0.4       ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.81926004,  0.18073996],\n",
       "       [ 0.98      ,  0.02      ],\n",
       "       [ 0.99      ,  0.01      ],\n",
       "       [ 0.99      ,  0.01      ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.01      ,  0.99      ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.8356171 ,  0.1643829 ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.06      ,  0.94      ],\n",
       "       [ 0.81926004,  0.18073996],\n",
       "       [ 0.41722799,  0.58277201],\n",
       "       [ 0.36      ,  0.64      ],\n",
       "       [ 0.365     ,  0.635     ],\n",
       "       [ 0.95347511,  0.04652489],\n",
       "       [ 0.84313509,  0.15686491],\n",
       "       [ 0.2110054 ,  0.7889946 ],\n",
       "       [ 0.8625    ,  0.1375    ],\n",
       "       [ 0.11      ,  0.89      ],\n",
       "       [ 0.5       ,  0.5       ],\n",
       "       [ 0.59783333,  0.40216667],\n",
       "       [ 0.97328571,  0.02671429],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.81926004,  0.18073996],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.08566667,  0.91433333],\n",
       "       [ 0.99666667,  0.00333333],\n",
       "       [ 0.14983053,  0.85016947],\n",
       "       [ 0.04857143,  0.95142857],\n",
       "       [ 0.96      ,  0.04      ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.87476399,  0.12523601],\n",
       "       [ 0.81926004,  0.18073996],\n",
       "       [ 0.86185775,  0.13814225],\n",
       "       [ 0.99      ,  0.01      ],\n",
       "       [ 0.64173846,  0.35826154],\n",
       "       [ 0.91      ,  0.09      ],\n",
       "       [ 0.99      ,  0.01      ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.03      ,  0.97      ],\n",
       "       [ 0.05      ,  0.95      ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.99666667,  0.00333333],\n",
       "       [ 0.15      ,  0.85      ],\n",
       "       [ 0.81926004,  0.18073996],\n",
       "       [ 0.81926004,  0.18073996],\n",
       "       [ 0.37611905,  0.62388095],\n",
       "       [ 0.0425    ,  0.9575    ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.87476399,  0.12523601],\n",
       "       [ 0.51683333,  0.48316667],\n",
       "       [ 0.7       ,  0.3       ],\n",
       "       [ 0.84684937,  0.15315063],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.97      ,  0.03      ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.02      ,  0.98      ],\n",
       "       [ 0.06      ,  0.94      ],\n",
       "       [ 0.02      ,  0.98      ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.93      ,  0.07      ],\n",
       "       [ 0.86251132,  0.13748868],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.94107048,  0.05892952],\n",
       "       [ 0.41502381,  0.58497619],\n",
       "       [ 0.92201587,  0.07798413],\n",
       "       [ 0.55316667,  0.44683333],\n",
       "       [ 0.99666667,  0.00333333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.96      ,  0.04      ],\n",
       "       [ 0.99862069,  0.00137931],\n",
       "       [ 0.93      ,  0.07      ],\n",
       "       [ 0.57916667,  0.42083333],\n",
       "       [ 0.95347511,  0.04652489],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.0675    ,  0.9325    ],\n",
       "       [ 0.99      ,  0.01      ],\n",
       "       [ 0.29      ,  0.71      ],\n",
       "       [ 0.44646902,  0.55353098],\n",
       "       [ 0.04888889,  0.95111111],\n",
       "       [ 0.8356171 ,  0.1643829 ],\n",
       "       [ 0.08566667,  0.91433333],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.86251132,  0.13748868],\n",
       "       [ 0.87476399,  0.12523601],\n",
       "       [ 0.2110054 ,  0.7889946 ],\n",
       "       [ 0.8       ,  0.2       ],\n",
       "       [ 0.69833333,  0.30166667],\n",
       "       [ 0.22      ,  0.78      ],\n",
       "       [ 0.95      ,  0.05      ],\n",
       "       [ 0.84684937,  0.15315063],\n",
       "       [ 0.73128571,  0.26871429],\n",
       "       [ 0.44646902,  0.55353098],\n",
       "       [ 0.73128571,  0.26871429],\n",
       "       [ 0.84313509,  0.15686491],\n",
       "       [ 0.433     ,  0.567     ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.87476399,  0.12523601],\n",
       "       [ 0.027     ,  0.973     ],\n",
       "       [ 0.88140861,  0.11859139],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.87044742,  0.12955258],\n",
       "       [ 0.61      ,  0.39      ],\n",
       "       [ 0.95033333,  0.04966667],\n",
       "       [ 0.08399172,  0.91600828],\n",
       "       [ 0.77824423,  0.22175577],\n",
       "       [ 0.02      ,  0.98      ],\n",
       "       [ 0.87476399,  0.12523601],\n",
       "       [ 0.95347511,  0.04652489],\n",
       "       [ 0.23029964,  0.76970036],\n",
       "       [ 0.08166667,  0.91833333],\n",
       "       [ 0.84684937,  0.15315063],\n",
       "       [ 0.07      ,  0.93      ],\n",
       "       [ 0.35      ,  0.65      ],\n",
       "       [ 0.87476399,  0.12523601],\n",
       "       [ 0.01      ,  0.99      ],\n",
       "       [ 0.8356171 ,  0.1643829 ],\n",
       "       [ 0.75759524,  0.24240476],\n",
       "       [ 0.82833333,  0.17166667],\n",
       "       [ 0.08      ,  0.92      ],\n",
       "       [ 0.16      ,  0.84      ],\n",
       "       [ 0.73270685,  0.26729315],\n",
       "       [ 0.92666667,  0.07333333],\n",
       "       [ 0.41722799,  0.58277201],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.        ,  1.        ],\n",
       "       [ 0.40433333,  0.59566667],\n",
       "       [ 0.99      ,  0.01      ],\n",
       "       [ 0.12683333,  0.87316667],\n",
       "       [ 0.84684937,  0.15315063],\n",
       "       [ 0.02      ,  0.98      ],\n",
       "       [ 0.86251132,  0.13748868],\n",
       "       [ 0.02566017,  0.97433983],\n",
       "       [ 0.33      ,  0.67      ],\n",
       "       [ 0.2110054 ,  0.7889946 ],\n",
       "       [ 0.08166667,  0.91833333],\n",
       "       [ 0.2110054 ,  0.7889946 ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.40433333,  0.59566667],\n",
       "       [ 0.67      ,  0.33      ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.03      ,  0.97      ],\n",
       "       [ 0.0475    ,  0.9525    ],\n",
       "       [ 0.77824423,  0.22175577],\n",
       "       [ 0.27166963,  0.72833037],\n",
       "       [ 0.6       ,  0.4       ],\n",
       "       [ 1.        ,  0.        ],\n",
       "       [ 0.5765    ,  0.4235    ],\n",
       "       [ 0.99      ,  0.01      ],\n",
       "       [ 0.59      ,  0.41      ],\n",
       "       [ 0.99      ,  0.01      ],\n",
       "       [ 0.87476399,  0.12523601],\n",
       "       [ 0.75      ,  0.25      ],\n",
       "       [ 0.86185775,  0.13814225],\n",
       "       [ 0.81926004,  0.18073996]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Random Forest Model\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(local_train_x,local_train_y)\n",
    "preds = clf.predict_proba(local_test_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check order of classes\n",
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82681564245810057"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy of Logistic Model\n",
    "preds.shape\n",
    "np.mean((preds[:,1] > 0.5) == local_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
